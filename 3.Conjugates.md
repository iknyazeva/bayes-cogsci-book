# Part 3 Conjugates and Predictive Distributions

## Conjugate Priors
A **conjugate prior** is a prior distribution that, when combined with a particular likelihood function, produces a posterior distribution of the same family as the prior.  
- Example: A **Beta prior** with a **Binomial likelihood** results in a **Beta posterior**.  
- Advantage: Makes Bayesian updating mathematically simple and analytically tractable.

## Conjugate Distributions
The pair of likelihood and prior that lead to this convenient property are called **conjugate distributions**.  
- For exponential family distributions (e.g., Binomial, Poisson, Normal), conjugate priors often exist.  
- This property helps avoid complex integrals when calculating posteriors.

## Predictive Prior Distribution
The **prior predictive distribution** represents the distribution of future or new data *before* observing any evidence.  
- It is obtained by integrating the likelihood over the prior distribution:  

$$
f(y) = \int f(y \mid \theta) \, f(\theta) \, d\theta
$$

- This captures uncertainty in both the parameter and the data.

## Predictive Posterior Distribution
The **posterior predictive distribution** describes the distribution of new data *after* observing evidence.  
- It integrates the likelihood over the **posterior distribution**:  

$$
f(y_{\text{new}} \mid y) = \int f(y_{\text{new}} \mid \theta) \, f(\theta \mid y) \, d\theta
$$

- It combines updated beliefs about parameters (posterior) with possible outcomes of new observations.

---

**In summary**:
- **Conjugate priors** make Bayesian updating easy.  
- **Conjugate distributions** are the matched prior-likelihood pairs.  
- **Prior predictive** shows data patterns before observing evidence.  
- **Posterior predictive** shows expected new data after incorporating evidence.
