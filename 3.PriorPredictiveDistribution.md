# Choosing a Prior

## Introduction

When selecting a prior, it's essential to represent our personal perspective, beliefs, and uncertainties. Theoretically, we are defining a cumulative distribution function (CDF) for the parameter of interest, $\theta$. This CDF represents the probability that $\theta$ is less than or equal to some value $c$ for all possible $c$ on the real line. Since this encompasses an infinite number of possibilities, defining probabilities coherently for each is impractical. Instead, we use more manageable approaches in practice.

## Practical Approach to Choosing a Prior

In practice, we work with a convenient family of distributions that is flexible enough to represent our beliefs. This family should allow us to incorporate external information, such as data from previous experiments. Typically, when we have sufficient data, the information within the data will dominate the influence of the prior. Consequently, the choice of prior has less impact on the posterior distribution.

### When the Prior Doesn't Matter Much

If the data is abundant, almost any reasonable prior will lead to approximately the same posterior distribution. However, some poor choices of priors can lead to misleading results. For instance, consider a prior that assigns a probability of 1 to $\theta = 0.5$ and a probability of 0 to any other value. This implies that our posterior distribution, $f(\theta \mid y)$, will just be $f(\theta)$, regardless of the data. In this case, the data has no influence on the posterior.

Such a prior is equivalent to a Dirac delta function at $0.5$, representing a point mass. This means:

- Events with prior probability of zero will have posterior probability of zero.
- Events with prior probability of one will have posterior probability of one.

A prudent Bayesian will avoid assigning probabilities of zero or one to events that are not absolutely certain.

## Calibration of Priors

A crucial concept in choosing priors is calibration, particularly the calibration of predictive intervals. For example, if we predict that 95% of new data points will fall within a certain interval, it would be beneficial if, in reality, 95% of new data points did fall within that interval. This type of calibration, though more aligned with frequentist ideas, is essential for ensuring that our results reflect reality accurately.

## Predictive Intervals

We can compute predictive intervals that describe where new observations are likely to fall. For instance, if we expect 95% of new observations to be within a particular range, this interval is for the data (e.g., $y$ or $x$), not the parameter $\theta$.

The predictive distribution for new data, $y$, before observing any actual data is given by:

$$
f(y) = \int f(y \mid \theta) \, f(\theta) \, d\theta
$$

This represents the integral of the joint density of $y$ and $\theta$, integrating out $\theta$ to obtain the marginal distribution for $y$. This is known as the prior predictive distribution, reflecting our beliefs before observing any data.

Choosing a prior is a balance between representing our prior beliefs and ensuring that it is flexible enough to be updated by data. A good prior should not be too rigid or too strong unless justified by solid prior knowledge. Calibration helps us ensure that our predictive intervals are reliable and reflect the true data-generating process.


# Predictive Distribution for Coin Flips

## Problem Setup

Suppose we're going to flip a coin 10 times and count the number of heads we observe. We are interested in the predictive distribution for the number of heads before actually flipping the coin. This prediction depends on the coin itself, specifically the probability $\theta$ that it shows heads.

## Prior Selection

We need to choose a prior for $\theta$. If we assume that all possible probabilities for heads are equally likely, we can choose a uniform prior over the interval $[0, 1]$.

## Defining the Predictive Distribution

Let $X$ be the number of heads observed in 10 flips. We can express $X$ as the sum of individual coin flips:

$$
X = \sum_{i=1}^{10} y_i
$$

where $y_i$ represents each individual coin flip, $Y_1$ through $Y_{10}$.

We are interested in the predictive distribution for $X$, which can take values 0, 1, 2, ..., up to 10. The predictive distribution $f(x)$ is given by the integral of the likelihood times the prior:

$$
f(x) = \int_0^1 f(x \mid \theta) \, f(\theta) \, d\theta
$$

### Binomial Likelihood

The likelihood $f(x \mid \theta)$ follows a binomial distribution because we are counting the total number of heads:

$$
f(x \mid \theta) = \binom{10}{x} \theta^x (1 - \theta)^{10 - x}
$$

Substitute this into the integral with a uniform prior $f(\theta) = 1$:

$$
f(x) = \int_0^1 \binom{10}{x} \theta^x (1 - \theta)^{10 - x} \cdot 1 \, d\theta
$$

### Simplification Using Beta Function

This integral can be difficult to compute directly, but we can simplify it using properties of the gamma and beta functions. Recall:

- The factorial function for integers $n$ is equivalent to the gamma function: $n! = \Gamma(n + 1)$.
- If $z$ follows a beta distribution with parameters $\alpha$ and $\beta$, the density function is:

$$
f(z) = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha) \Gamma(\beta)} z^{\alpha - 1} (1 - z)^{\beta - 1}
$$

We can rewrite our integral in terms of a beta distribution.

### Rewriting the Integral

Let's express the binomial coefficient $\binom{10}{x}$ and the rest of the integrand in terms of the gamma function:

$$
\binom{10}{x} = \frac{\Gamma(11)}{\Gamma(x + 1) \Gamma(11 - x)}
$$

Rewriting the integral:

$$
f(x) = \int_0^1 \frac{\Gamma(11)}{\Gamma(x + 1) \Gamma(11 - x)} \theta^{x} (1 - \theta)^{10 - x} \, d\theta
$$

We notice that this is the form of a beta distribution with parameters $\alpha = x + 1$ and $\beta = 11 - x$. Therefore, the integral simplifies to:

$$
f(x) = \frac{\Gamma(11)}{\Gamma(x + 1) \Gamma(11 - x)} \frac{\Gamma(x + 1) \Gamma(11 - x)}{\Gamma(12)}
$$

### Final Simplification

Simplifying further:

$$
f(x) = \frac{\Gamma(11)}{\Gamma(12)} = \frac{10!}{11!} = \frac{1}{11}
$$

This result tells us that the predictive distribution for $X$ is discrete uniform, meaning each possible value of $X$ (0 through 10) is equally likely with probability $\frac{1}{11}$.

## Conclusion

If we assume a uniform prior over $[0, 1]$ for $\theta$, then the predictive distribution for the number of heads in 10 flips, $X$, is a discrete uniform distribution. This means that every possible outcome (0 through 10 heads) has an equal probability of $\frac{1}{11}$.

This analysis demonstrates that if all possible coin probabilities are considered equally likely, then all possible head counts are also equally likely.


