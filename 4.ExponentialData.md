# Bayesian Inference with Exponential Data

## Scenario
Let's consider the case of **exponential data**. Suppose you're waiting for a bus that you believe arrives, on average, once every ten minutes, but you're unsure of the exact rate. The waiting time,$Y$, follows an **exponential distribution** with an unknown rate parameter$\lambda$. 

In this model, the prior expectation of your waiting time is:

$$
E[\text{Waiting time}] = \frac{1}{\lambda}
$$

## Gamma Distribution as a Conjugate Prior

The **gamma distribution** is the conjugate prior for an **exponential likelihood**. This means that if the likelihood follows an exponential distribution, then the posterior distribution will also follow a gamma distribution when we use a gamma prior.

### Setting the Prior
To define our prior, we need to consider the rate of the bus's arrival. If we think buses arrive, on average, once every 10 minutes, the rate parameter$\lambda$ is:

$$
\lambda = \frac{1}{10}
$$

This gives us a prior mean of$\frac{1}{10}$. We can use a **Gamma distribution** for$\lambda$, with the first parameter (shape) and second parameter (rate) such that:

$$
\frac{\text{shape}}{\text{rate}} = \frac{1}{10}
$$

For example, let's specify a prior distribution for $\lambda$ as $\text{Gamma}(100, 1000)$, which gives us:

- Prior mean:$\frac{100}{1000} = \frac{1}{10}$
- Prior standard deviation:$\frac{1}{100}$

Thus, using a rough approximation of **mean Â± two standard deviations**, we expect the rate parameter $\lambda$ to be in the range $0.1 \pm 0.02$.

### Updating with Data: The Posterior Distribution
Now, suppose you wait for **12 minutes**, and a bus arrives. You want to update your belief about $\lambda$ using **Bayesian inference**. The posterior distribution for $\lambda$ is proportional to the likelihood times the prior.

### Likelihood and Prior
The likelihood of observing $Y$ given $\lambda$ for exponential data is:

$$
L(\lambda \mid Y) = \lambda e^{-\lambda Y}
$$

The gamma prior for$\lambda$ is:

$$
\pi(\lambda) = \lambda^{\alpha - 1} e^{-\beta \lambda}
$$

Multiplying the likelihood and prior gives the posterior distribution:

$$
\pi(\lambda \mid Y) \propto \lambda^{\alpha + 1 - 1} e^{-(\beta + Y)\lambda}
$$

This is in the form of a **gamma distribution**, so the posterior for $\lambda$ follows:

$$
\lambda \mid Y \sim \text{Gamma}(\alpha + 1, \beta + Y)
$$

### Example Calculation
Given our prior$\text{Gamma}(100, 1000)$ and after observing $Y = 12$, the posterior distribution becomes:

$$
\lambda \mid Y \sim \text{Gamma}(101, 1012)
$$

The posterior mean is:

$$
\text{Posterior mean} = \frac{101}{1012} \approx 0.0998
$$

This is close to $\frac{1}{10.02}$, so after observing 12 minutes, our belief slightly adjusts. The posterior mean shifts upward, suggesting a slightly longer expected waiting time, but **one data point** doesn't have a large impact on the posterior due to the prior's strength.

## Key Takeaways
- **Gamma distribution** is conjugate for an **exponential likelihood**.
- The posterior distribution can be easily updated using the **gamma** form with new data.
- With a strong prior and limited data, the posterior distribution won't shift much.

In this example, observing a bus after 12 minutes slightly increases our posterior mean waiting time, but the change is small due to the weight of the prior information. Notice, that effective sample size for our prior equal 1000!
