# Assessing Convergence of Markov Chains


Before using simulated chains to obtain Monte Carlo estimates, we should ask ourselves the following question:

**Has our simulated Markov chain converged to its stationary distribution yet?**

Unfortunately, this is a difficult question to answer, but we can do several things to investigate. Throughout this lesson, we will focus less on the code and more on the plots.

## Visual Tool : The Trace Plot

Our first visual tool for assessing chains, and one you've already seen in previous examples, is the **trace plot**. Here's an example of a trace plot. A trace plot shows the history of a parameter value across iterations of the chain. On the x-axis, we have the number of iterations, and it shows you where the chain has been exploring.

### Example: A Chain That Has Converged

A chain that has converged will not show any long-term trends. The average value of the chain should be roughly flat. Here is an example of a chain that has most likely converged:

- It looks like it's approximately a normal distribution across iterations.
  
### Example: A Chain That Is Wandering

Now, let's look at an example where the step size of the random walk sampler is too small, so it takes many iterations for the chain to traverse across the distribution. We are seeing long-term trends. For instance, if you estimate the mean using only the first 200 iterations, you get a different result than using iterations 600-800.

In this case, you need to run the chain for many more iterations. Here's the same chain over a much larger time scale (e.g., 100,000 iterations). On this larger scale, it appears that the chain has converged.

## Autocorrelation and Effective Sample Size

Another key difference between the two chains is the level of **autocorrelation**. Autocorrelation measures how linearly dependent the current value of the chain is on past values (lags). You can inspect autocorrelation using the **autocorrelation plot**.

### Example: Low Autocorrelation in a Converged Chain

In our good example of a converged chain, autocorrelation decreases quickly as lag increases. The value of the chain at lag 1 has a correlation of around 0.5, and by lag 10, it approaches zero.

### Example: High Autocorrelation in a Non-Converged Chain

In the example with a smaller step size, the chain exhibits extreme autocorrelation. Even after 30 lags, the autocorrelation remains above 0.5. High autocorrelation means that the chain is highly correlated with its previous values, reducing the amount of useful information in the chain.

### The Importance of Autocorrelation

Autocorrelation reduces the **Monte Carlo effective sample size**, which tells us how much information the chain provides. For example, a chain of 1000 highly autocorrelated samples gives less information than 1000 independent samples.

To illustrate, consider trying to estimate the most popular movie in your town by asking 20 random people versus asking 20 of your friends. Since your friends' opinions are correlated, you'd need more people to get the same quality of information that a random sample would provide.

### Calculating the Effective Sample Size

The effective sample size is a measure of how many independent samples from the stationary distribution you'd need to match the information in your Markov chain. Chains with high autocorrelation will have a much smaller effective sample size. Here's an example of calculating the effective sample size of our highly autocorrelated chain:

- Despite simulating 100,000 samples, the effective sample size might only be around 373 due to autocorrelation.

## Thinning the Chain

One method to reduce autocorrelation is **thinning**. By only keeping every nth iteration of the chain, you can reduce autocorrelation. For example, thinning the chain by keeping every 400th iteration can result in a chain with low autocorrelation and a higher effective sample size.

After thinning, the trace plot looks smoother, and the autocorrelation is nearly gone. The effective sample size of this thinned chain will be closer to the number of actual samples kept.

### Comparison of Effective Sample Sizes

Let's compare the effective sample size of a good, well-mixed chain with 4,000 iterations and a poorly mixed chain with 100,000 iterations:

- The good chain has an effective sample size of nearly 1,000 out of 4,000.
- The poorly mixed chain has an effective sample size of 373 out of 100,000.

Clearly, autocorrelation dramatically reduces the effective sample size and the amount of useful information in the chain.

## Raftery and Lewis Diagnostic

If you're looking for a more precise method to assess whether your chain has enough samples, the **Raftery and Lewis diagnostic** can help. It estimates the number of iterations you need to accurately estimate specific quantiles of the distribution. You can calculate this using the `raftery.diag` function in the `coda` package (or its equivalent in Python).

For example, the Raftery and Lewis diagnostic might tell you that to estimate the 0.25 quantile of the distribution with 95% confidence, you'd need 12,000 iterations due to autocorrelation.

## Gelman-Rubin Diagnostic


The **Potential Scale Reduction Factor (PSRF)**, also known as the Gelman-Rubin diagnostic, is a metric used to assess the convergence of MCMC chains. It compares the variance **within chains** to the variance **between chains** to evaluate whether the chains have converged to the same stationary distribution.

### PSRF Formula

The PSRF, denoted as $\hat{R}$, is calculated as:

$$
\hat{R} = \sqrt{\frac{\hat{V}}{W}}
$$

Where:
- **$\hat{V}$**: An estimate of the target variance, combining both within-chain and between-chain variances.
- **$W$**: The within-chain variance.
- **$B$**: The between-chain variance.

**Estimation of $\hat{V}$**

$$
\hat{V} = \frac{n - 1}{n}W + \frac{1}{n}B
$$

Where:
- $n$: Number of iterations in each chain.
- $W$: Within-chain variance.
- $B$: Between-chain variance.

**Within-Chain Variance ($W$)**

$$
W = \frac{1}{m} \sum_{j=1}^m s_j^2
$$

Where:
- $s_j^2$: Variance of chain $j$.
- $m$: Number of chains.

---

**Between-Chain Variance ($B$)**

$$
B = \frac{n}{m - 1} \sum_{j=1}^m (\bar{\theta}_j - \bar{\theta})^2
$$

Where:
- $\bar{\theta}_j$: Mean of chain $j$.
- $\bar{\theta}$: Overall mean across all chains.

---

 **Interpretation of PSRF ($\hat{R}$)**

1. **$\hat{R} \approx 1$:**
   - Indicates that the chains have converged.
   - The within-chain and between-chain variances are similar, suggesting the chains are sampling from the same stationary distribution.

2. **$\hat{R} > 1$:**
   - Indicates that the chains have not yet converged.
   - Values significantly greater than 1 suggest substantial differences between chains or insufficient mixing.

- Multiple chains are run with diverse starting points.
- Chains are run for enough iterations to provide reasonable estimates of $W$ and $B$.

The PSRF provides a robust diagnostic for MCMC convergence, helping ensure that samples are representative of the target posterior distribution.


## Conclusion

To summarize:

1. Use **trace plots** to visually inspect convergence.
2. Check the **autocorrelation** of your chain to assess how much information the chain provides.
3. Calculate the **effective sample size** to determine how many independent samples your chain provides.
4. Use thinning to reduce autocorrelation, but recognize that you are discarding data.
5. Use the **Raftery and Lewis diagnostic** for precise estimates of the number of iterations needed.
6. To confirm convergence, simulate **multiple chains** with different starting values and Gelman-Rubin Diagnostic for diagnostics
7. Once convergence is achieved, discard the burn-in period (e.g., first 1000 iterations).

Effective sample size is crucial for making reliable estimates in MCMC simulations, and autocorrelation is a key factor to consider in your analysis.
ping only every nth iteration to reduce autocorrelation. Let's see how thinning impacts the chain.
