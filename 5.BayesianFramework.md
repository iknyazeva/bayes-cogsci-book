# Part 5. Bayesian Modelling Framework

The following two chapters — **Bayesian Modelling Steps** and **Linear Regression** — introduce the foundations and practical application of Bayesian statistics in modeling relationships between data and parameters.


## Chapter Overview

###  Bayesian Modelling Steps

This chapter provides a conceptual and procedural overview of the statistical modeling process, with an emphasis on **Bayesian reasoning**.  
You’ll learn:
- Why we build statistical models and what questions they answer.  
- The major **objectives of statistical inference** — uncertainty quantification, inference, hypothesis testing, and prediction.  
- How Bayesian models are defined through **likelihoods**, **priors**, and **posteriors**.  
- The **hierarchical structure** of models and their graphical representation.  
- How to extend models by introducing **hyperpriors** and **non-conjugate priors**.  

Together, these concepts form the backbone of Bayesian thinking — modeling uncertainty explicitly and updating beliefs through observed data.

---

###  Linear Regression

The second chapter builds on this foundation by introducing one of the most widely used statistical models — **linear regression** — in a **Bayesian framework**.  
It demonstrates:
- How **linear dependence** between variables can be expressed probabilistically.  
- How to specify a **likelihood** with linear dependence on parameters, such as in Gaussian or exponential families.  
- How to assign appropriate **prior distributions** to regression coefficients and variance parameters.  
- How posterior inference provides full uncertainty estimates for model parameters and predictions.  

The chapter also shows that, in Bayesian modeling, linear relationships are not restricted to classical regression. You can define **linear dependencies among any parameters** of the likelihood — for example, setting the **mean of an exponential-Gaussian model** to depend linearly on a predictor variable.

